# ğŸ¤– AI Engine v5 - Autonomous French News Curation

**The Next Generation: Fully Autonomous, Intelligent, and Self-Contained**

AI Engine v5 represents a complete architectural revolution in the Better French system, solving key problems with a **separated workflow approach** that runs autonomously without human intervention.

## ğŸš€ Key Innovation: Separated Workflows

### Problem Solved
Previous versions suffered from:
- ğŸ”„ Repeated scraping during development/testing
- ğŸ“Š Bulk processing issues (1000+ articles)
- ğŸ• Time-consuming manual operations
- ğŸ’¸ Unpredictable costs
- ğŸ§  "Heat wave spam" - repetitive similar articles

### V5 Solution: Autonomous Architecture

```mermaid
graph TD
    A[ğŸ• Hourly Scraper] --> B[ğŸ“¦ Scraper Data File]
    B --> C[ğŸ” Website Processor]
    C --> D[ğŸŒ Enhanced Website]
    
    E[âš¡ Every Hour] --> A
    F[âš¡ Every 30 min] --> C
    
    A --> G[ğŸ¤– Gemini 2.5 Flash<br/>Select Top 10]
    C --> H[ğŸ§  V3 + V4 Pipeline<br/>Enhancement]
```

## ğŸ—ï¸ Architecture Overview

### 1. ğŸ¤– Autonomous Scraper (Hourly)
- **Purpose**: Minimal, fast news collection
- **Frequency**: Every hour (Paris time)
- **Process**:
  1. âœ… Check if current hour already processed
  2. ğŸ“¡ Scrape French news sources (7 RSS feeds)
  3. ğŸ§  Use Gemini 2.5 Flash to select top 10 articles
  4. ğŸ’¾ Store in single `scraper_data.json` file
  5. â­ï¸ Exit (no heavy processing)

### 2. ğŸŒ Website Processor (File Detection)
- **Purpose**: Apply V3+V4 enhancement pipeline
- **Frequency**: Every 30 minutes
- **Process**:
  1. ğŸ” Detect unprocessed articles from scraper
  2. ğŸ¤– Apply V3 enhancement (Gemini 2.0 Flash)
  3. âœ¨ Apply V4 enhancement (GPT-4o mini)
  4. ğŸŒ Generate enhanced website
  5. ğŸ“ Mark articles as processed

### 3. ğŸ“¦ Single File Data Management
- **`scraper_data.json`**: Contains everything
  - Scraper state (last processed hour)
  - Collected articles by hour
  - Processing status flags
  - Cost tracking
- **Benefits**: Clean, predictable, easy to debug

## ğŸ¯ Benefits for Developers

### âœ… Autonomous Operation
- Scraper runs every hour regardless of development work
- No more repeated scraping during testing
- Work with stored hourly data for development
- Predictable costs and processing

### âœ… Separated Concerns
- **Scraper**: Fast, minimal LLM usage
- **Processor**: Heavy enhancement only when needed
- Clear separation of responsibilities
- Independent scaling and optimization

### âœ… Robust Error Handling
- Graceful fallbacks at every step
- Placeholder mode for development
- Cost tracking and limits
- Detailed logging and status

## ğŸ”§ Installation & Setup

```bash
# Install AI Engine v5 (self-contained)
cd ai_engine_v5
pip install -e .

# Set environment variables
export OPENROUTER_API_KEY="your_api_key_here"
export AI_ENGINE_SELECTION_MODEL="google/gemini-2.0-flash-exp"
export AI_ENGINE_V3_MODEL="google/gemini-2.0-flash-exp"
export AI_ENGINE_V4_MODEL="openai/gpt-4o-mini"
```

## ğŸš€ Usage

### Autonomous Mode (Production)
The system runs automatically via GitHub Actions:
- **Scraper**: `.github/workflows/data_collection.yml` (hourly)
- **Processor**: `.github/workflows/ai_processing.yml` (every 30 min)

### Manual Testing (Development)
```python
from ai_engine_v5.core.scraper.autonomous_scraper import AutonomousScraper
from ai_engine_v5.core.processor.website_processor import WebsiteProcessor

# Test scraper
scraper = AutonomousScraper()
candidates = scraper.scrape_current_hour()
result = scraper.llm_select_top_10(candidates)

# Test processor
processor = WebsiteProcessor()
enhanced, cost = processor.enhance_articles(result['selected_articles'])
website = processor.generate_website(enhanced)
```

## ğŸ“Š Data Flow

```
Hourly Scraper âœ scraper_data.json âœ Website Processor âœ Enhanced Website
     â¬‡ï¸                    â¬‡ï¸                  â¬‡ï¸              â¬‡ï¸
ğŸ“¡ RSS feeds         ğŸ’¾ Single file      ğŸ§  V3+V4 pipeline  ğŸŒ betterfrench.io/v5-site/
ğŸ¤– LLM selection     ğŸ“Š Status tracking  âœ¨ Enhancement      ğŸ“± Mobile-friendly
ğŸ’° $0.01-0.05       ğŸ• Hour tracking    ğŸ’° $0.10-0.50      ğŸ¨ Modern UI
```

## ğŸ›ï¸ Configuration

### Scraper Settings
```python
# In autonomous_scraper.py
SOURCES = [
    "https://www.lemonde.fr/rss/une.xml",
    "https://www.lefigaro.fr/rss/figaro_une.xml",
    # ... 7 total sources
]
SELECTION_MODEL = "google/gemini-2.0-flash-exp"  # Fast, cheap
HOURLY_LIMIT = 10  # Articles per hour
```

### Processor Settings
```python
# In website_processor.py
V3_MODEL = "google/gemini-2.0-flash-exp"  # Simplification
V4_MODEL = "openai/gpt-4o-mini"          # Quality verification
BATCH_LIMIT = 50  # Max articles per run
```

## ğŸ§  Intelligent Features

### 1. Smart Deduplication
- Title-based hashing prevents exact duplicates
- LLM selection considers topic diversity
- No more "heat wave spam"

### 2. Learning-Focused Curation
- Educational value prioritization
- B1-B2 French level optimization
- Diverse topic selection

### 3. Cost Optimization
- Gemini 2.5 Flash for selection (~$0.01)
- Gemini 2.0 Flash for V3 (~$0.05)
- GPT-4o mini for V4 verification (~$0.10)
- Total: ~$0.16 per 10 articles

### 4. Quality Enhancement Pipeline
- **V3**: Simplification + vocabulary extraction
- **V4**: GPT-4o verification + tooltip quality
- **Result**: Learner-optimized content

## ğŸ“ˆ Performance Metrics

| Metric | V3/V4 | V5 Autonomous |
|--------|-------|---------------|
| Scraping Speed | 5-10 min | 2-3 min |
| Processing Time | 15-30 min | 5-10 min |
| Cost per 10 articles | $0.20-0.50 | $0.15-0.25 |
| Manual Intervention | Required | Zero |
| Duplicate Articles | Common | Eliminated |
| Development Impact | High | None |

## ğŸ”® Future Enhancements

### Phase 1: Core Stability
- [x] Autonomous scraper implementation
- [x] Website processor implementation
- [x] Single file data management
- [ ] Enhanced error recovery
- [ ] Performance monitoring

### Phase 2: Intelligence Upgrades
- [ ] Semantic similarity detection
- [ ] User preference learning
- [ ] Advanced topic clustering
- [ ] Pronunciation hints

### Phase 3: Scale & Optimization
- [ ] Multi-language support
- [ ] Regional content customization
- [ ] Advanced caching strategies
- [ ] Real-time updates

## ğŸ¤ Contributing

AI Engine v5 is designed to be self-contained and autonomous. When contributing:

1. **Test Autonomously**: Don't rely on manual processes
2. **Preserve Separation**: Keep scraper and processor independent
3. **Monitor Costs**: Track LLM usage carefully
4. **Document Changes**: Update this README

## ğŸ“Š System Status

- ğŸŸ¢ **Autonomous Scraper**: Active (hourly)
- ğŸŸ¢ **Website Processor**: Active (30-minute intervals)
- ğŸŸ¢ **V5 Website**: Live at [betterfrench.io/v5-site/](https://sonianand07.github.io/Better-French/v5-site/)
- ğŸŸ¢ **Cost Tracking**: Monitored and optimized

---

**ğŸ¯ Result**: A fully autonomous French news curation system that learns, adapts, and enhances content without human intervention while maintaining high quality and cost efficiency. 