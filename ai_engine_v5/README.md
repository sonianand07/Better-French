# AI Engine v5: Intelligent Separated Architecture

## ðŸŽ¯ **Core Innovation: Intelligent Topic-Aware Curation**

AI Engine v5 solves the fundamental problems of v3/v4:
- **No more bulk processing overload** (separated workflows)
- **Intelligent semantic deduplication** (heat wave = heat waves)
- **Topic-aware selection** (avoids bombarding same news themes)
- **Website-aware curation** (considers existing 100 articles)

## ðŸ—ï¸ **Two-Workflow Architecture**

### Workflow 1: Data Collection (Hourly)
```yaml
name: Collect & Curate News - v5
schedule: '0 * * * *'  # Every hour
```
**What it does:**
- Scrapes news sources
- Applies semantic deduplication
- Analyzes topics vs existing website content
- Selects 10 truly NEW/DIFFERENT articles
- Stores in `ai_engine_v5/data/collected/hourly_batch_YYYYMMDD_HH.json`

### Workflow 2: AI Processing (On-demand)
```yaml
name: Process Collected Articles - v5
workflow_dispatch: true  # Manual trigger
```
**What it does:**
- Reads collected batches
- Applies V3 processing (Gemini 2.5 Flash)
- Applies V4 verification (GPT-4o-mini)
- Deploys enhanced websites
- Preserves development data for iteration

## ðŸ§  **Intelligent Curation System**

### Problem Solved:
âŒ **Before:** "Heat wave in Paris", "Heat waves continue in France", "Paris swelters in heat"
âœ… **After:** AI Engine v5 recognizes these as the SAME story and picks the best one

### How It Works:

#### 1. **Semantic Deduplication**
```python
# Instead of simple string matching
if article.title == existing.title:  # âŒ Miss semantic duplicates

# v5 uses semantic similarity
if semantic_similarity(article, existing) > 0.85:  # âœ… Catches variations
```

#### 2. **Topic Analysis**
```python
# Analyze what topics are already covered on website
existing_topics = analyze_website_topics(current_articles)
# ["heat_wave", "politics", "sports", "economy"]

# Score new articles based on topic diversity
for article in candidates:
    topic_score = calculate_topic_novelty(article, existing_topics)
```

#### 3. **Quality-Based Selection**
```python
# When multiple articles cover same topic, pick the best one
if topic_overlap:
    selected = max(articles, key=lambda x: x.quality_score)
```

## ðŸ“Š **Data Flow**

```
[News Sources] 
    â†“
[Hourly Scraper] (raw articles)
    â†“
[Semantic Deduplicator] (removes duplicates)
    â†“
[Topic Analyzer] (analyzes vs website)
    â†“
[Quality Selector] (picks best 10)
    â†“
[Collected Batch] â†’ hourly_batch_YYYYMMDD_HH.json
    â†“
[AI Processor] (when triggered)
    â†“
[V3 + V4 Enhancement]
    â†“
[Website Deployment]
```

## ðŸŽ¯ **Development Benefits**

### **Preserved V3/V4 Capabilities:**
- âœ… V3 processing (simplified titles, summaries, tooltips)
- âœ… V4 verification (quality checking, error correction)
- âœ… Dual website deployment (comparison)

### **New v5 Advantages:**
- ðŸ”¥ **No bulk processing** - AI only sees 10 articles max
- ðŸ§  **Semantic intelligence** - recognizes topic variations
- ðŸ“Š **Website awareness** - considers existing content
- ðŸš€ **Development friendly** - work with same data during iteration
- ðŸ’° **Cost predictable** - bounded AI usage
- ðŸ”§ **Easy debugging** - separate scraping from processing

## ðŸ“ˆ **Expected Results**

### **Website Quality:**
- **More diverse topics** (no heat wave spam)
- **Higher quality articles** (best of each topic)
- **Balanced coverage** (politics + sports + culture, not just politics)

### **Operational Efficiency:**
- **10 articles per batch** instead of 1,000+
- **Predictable costs** (~$0.50 per processing run)
- **Faster iteration** (work with cached data during development)
- **Better monitoring** (clear separation of concerns)

## ðŸš€ **Implementation Roadmap**

### Phase 1: Intelligent Curator
- [ ] Semantic similarity engine
- [ ] Topic analysis system
- [ ] Website content analyzer
- [ ] Quality-based selector

### Phase 2: Data Collection Workflow
- [ ] Hourly scraper workflow
- [ ] Collected data storage
- [ ] Batch management system

### Phase 3: AI Processing Workflow
- [ ] V3 processing integration
- [ ] V4 verification integration
- [ ] Dual website deployment

### Phase 4: Development Tools
- [ ] Data replay system
- [ ] Topic visualization
- [ ] Quality metrics dashboard

**ðŸŽ¯ Goal: Launch v5 with first intelligent batch by next week!** 